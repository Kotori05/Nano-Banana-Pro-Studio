## Ethical Statement

# This project is released under the GNU AGPL v3 license.

# It is intended for:
# - Free personal use
# - Free research use
# - Free non-commercial sharing
# - Open collaborative improvement

# This project is **NOT intended to be used for**:
# - Knowledge-paywall products
# - Information arbitrage
# - Closed-source commercial GUI repackaging
# - Paid courses based primarily on this tool without original contribution

# If you use this project commercially, you must:
# - Open-source all your modifications under AGPL v3
# - Clearly credit the original project
# - Notify users that a free open-source version exists

# Respect creators. Respect users.


import os
import mimetypes
from typing import List, Dict, Any, Tuple

import gradio as gr
from google import genai
from google.genai import types

import os
from pathlib import Path
import json

import re
from datetime import datetime
from PIL import Image

import uuid
from datetime import datetime
import socket

from pprint import pprint
import importlib.util
import sys

# é¢„è®¾é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_PATH = Path("config.json")

# åŠ¨æ€åŠ è½½æ’ä»¶
def load_plugins_from_dir(plugin_dir: str = "plugins"):
    """
    åŠ¨æ€æ‰«ææŒ‡å®šç›®å½•ï¼ŒåŠ è½½åŒ…å« create_tab å‡½æ•°çš„æ’ä»¶
    """
    if not os.path.exists(plugin_dir):
        print(f"[INFO] æ’ä»¶ç›®å½• {plugin_dir} ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚")
        return

    # éå†ç›®å½•ä¸‹çš„ .py æ–‡ä»¶
    for filename in os.listdir(plugin_dir):
        if filename.endswith(".py") and not filename.startswith("__"):
            file_path = os.path.join(plugin_dir, filename)
            module_name = filename[:-3] # å»æ‰ .py
            
            try:
                # åŠ¨æ€åŠ è½½æ¨¡å—
                spec = importlib.util.spec_from_file_location(module_name, file_path)
                if spec and spec.loader:
                    module = importlib.util.module_from_spec(spec)
                    sys.modules[module_name] = module
                    spec.loader.exec_module(module)
                    
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ create_tab å‡½æ•°
                    if hasattr(module, "create_tab") and callable(module.create_tab):
                        print(f"[PLUGIN] æ­£åœ¨åŠ è½½æ’ä»¶: {filename} ...")
                        # æ‰§è¡Œæ’ä»¶æ„å»ºé€»è¾‘
                        module.create_tab()
                    else:
                        print(f"[PLUGIN] è·³è¿‡ {filename}: æœªæ‰¾åˆ° 'create_tab' å‡½æ•°")
            except Exception as e:
                print(f"[ERROR] åŠ è½½æ’ä»¶ {filename} å¤±è´¥: {e}")

# æ‰“å°è¯·æ±‚æŠ¥æ–‡
def _debug_print_send(model_name, system_instruction, user_text, image_files, generate_config=None, contents=None):
    print("\n" + "=" * 80)
    print("[SEND] Gemini Request")
    print("Model:", model_name)

    if system_instruction:
        print("\n[System Instruction]\n", system_instruction)

    if user_text:
        print("\n[User Text]\n", user_text)

    if image_files:
        print("\n[User Images]")
        for i, img in enumerate(image_files):
            p = img.name if hasattr(img, "name") else img
            print(f"  [{i}] {p}")

    if contents is not None:
        print("\n[Contents]")
        pprint(contents)

    if generate_config is not None:
        print("\n[Generate Config]")
        # google-genai çš„å¯¹è±¡é€šå¸¸æœ‰ model_dumpï¼›æ²¡æœ‰å°± pprint
        try:
            pprint(generate_config.model_dump())
        except Exception:
            pprint(generate_config)

    print("=" * 80 + "\n")

# æ‰“å°æ¥å—æŠ¥æ–‡
def _debug_print_recv(response):
    import json
    print("\n" + "=" * 80)
    print("[RECV] Gemini Response")
    try:
        print(json.dumps(response.model_dump(), ensure_ascii=False, indent=2))
    except Exception:
        pprint(response)
    print("=" * 80 + "\n")

def find_free_port(start: int = 7860, end: int = 7880, host: str = "127.0.0.1") -> int:
    for port in range(start, end + 1):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            try:
                s.bind((host, port))
                return port
            except OSError:
                continue
    raise RuntimeError(f"No free port found in range {start}-{end}")

def load_presets_from_config() -> Dict[str, Any]:
    """
    ä» config.json è¯»å–å‚æ•°é¢„è®¾ï¼Œæ ¼å¼ï¼š
    {
      "presets": {
        "åç§°": { ...å‚æ•°... },
        ...
      }
    }
    """
    if not CONFIG_PATH.exists():
        return {}
    try:
        data = json.load(CONFIG_PATH.open("r", encoding="utf-8"))
        if isinstance(data, dict):
            if "presets" in data and isinstance(data["presets"], dict):
                return data["presets"]
            # å…¼å®¹æ—§æ ¼å¼ï¼šæ•´ä¸ª json å°±æ˜¯ presets
            return data
    except Exception as e:
        print(f"[WARN] è¯»å– config.json å¤±è´¥ï¼š{e}")
    return {}


def save_presets_to_config(presets: Dict[str, Any]) -> None:
    """
    å°†é¢„è®¾å†™å› config.json
    """
    data = {"presets": presets}
    try:
        CONFIG_PATH.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"[INFO] å·²ä¿å­˜å‚æ•°é¢„è®¾åˆ° {CONFIG_PATH}")
    except Exception as e:
        print(f"[ERROR] å†™å…¥ config.json å¤±è´¥ï¼š{e}")


def save_preset(
    preset_name: str,
    presets: Dict[str, Any],
    model_name: str,
    aspect_ratio: str,
    image_size: str,
    temperature: float,
    top_p: float,
    top_k: int,
    max_output_tokens: int,
    system_instruction: str,
):
    """
    Gradio å›è°ƒï¼šä¿å­˜å½“å‰å‚æ•°ä¸ºä¸€ä¸ªé¢„è®¾ã€‚
    è¿”å›æ›´æ–°åçš„ presets_state å’Œ preset_dropdownã€‚
    """
    name = (preset_name or "").strip() or "default"
    presets = dict(presets or {})
    presets[name] = {
        "model_name": model_name,
        "aspect_ratio": aspect_ratio,
        "image_size": image_size,
        "temperature": float(temperature),
        "top_p": float(top_p),
        "top_k": int(top_k),
        "max_output_tokens": int(max_output_tokens),
        "system_instruction": system_instruction,
    }
    save_presets_to_config(presets)
    choices = list(presets.keys())
    return presets, gr.update(choices=choices, value=name)


def load_preset(
    selected_name: str,
    presets: Dict[str, Any],
):
    """
    Gradio å›è°ƒï¼šæ ¹æ®é€‰æ‹©çš„é¢„è®¾ï¼ŒåŠ è½½å‚æ•°åˆ° UIã€‚
    è¿”å›é¡ºåºï¼šmodel_name, aspect_ratio, image_size,
             temperature, top_p, top_k, max_output_tokens, system_instruction
    """
    if not selected_name or selected_name not in (presets or {}):
        # ä¸æ”¹åŠ¨å½“å‰å€¼
        upd = gr.update()
        return upd, upd, upd, upd, upd, upd, upd, upd

    p = presets[selected_name]
    def get_or_update(key, default=None):
        return p.get(key, default if default is not None else gr.update())

    return (
        get_or_update("model_name"),
        get_or_update("aspect_ratio"),
        get_or_update("image_size"),
        get_or_update("temperature"),
        get_or_update("top_p"),
        get_or_update("top_k"),
        get_or_update("max_output_tokens"),
        get_or_update("system_instruction", ""),
    )


def delete_preset(
    selected_name: str,
    presets: Dict[str, Any],
):
    """
    Gradio å›è°ƒï¼šåˆ é™¤å½“å‰é€‰ä¸­çš„é¢„è®¾ã€‚
    è¿”å›æ›´æ–°åçš„ presets_state å’Œ preset_dropdownã€‚
    """
    presets = dict(presets or {})
    if selected_name in presets:
        del presets[selected_name]
        save_presets_to_config(presets)
    choices = list(presets.keys())
    new_value = choices[0] if choices else None
    return presets, gr.update(choices=choices, value=new_value)

def load_google_api_key_from_file() -> None:
    """
    å°è¯•åŒæ—¶åŠ è½½ 'GOOGLE_CLOUD_API_KEY.json' (Vertex) å’Œ 'GOOGLE_CLOUD_API_KEY.txt' (AI Studio)ã€‚
    å°†æ‰€æœ‰æ‰¾åˆ°çš„å‡­è¯éƒ½å†™å…¥ç¯å¢ƒå˜é‡ï¼Œä¾›åç»­é€»è¾‘é€‰ç”¨ã€‚
    """
    # === 1. è¯»å– Vertex JSON (Service Account) ===
    vertex_json_path = Path("GOOGLE_CLOUD_API_KEY.json")
    if vertex_json_path.exists() and vertex_json_path.is_file():
        try:
            abs_path = str(vertex_json_path.resolve())
            with open(vertex_json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                project_id = data.get("project_id")
            
            if project_id:
                os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = abs_path
                os.environ["GOOGLE_CLOUD_PROJECT"] = project_id
                print(f"[INFO] å·²åŠ è½½ Vertex å‡­è¯: {vertex_json_path.name} (Project: {project_id})")
            else:
                print(f"[WARN] {vertex_json_path} ç¼ºå°‘ 'project_id' å­—æ®µï¼Œè·³è¿‡ Vertex åŠ è½½ã€‚")
        except Exception as e:
            print(f"[ERROR] è¯»å– Vertex JSON å¤±è´¥: {e}")
    
    # === 2. è¯»å– AI Studio API Key ===
    # (ä¸ç®¡ä¸Šé¢æ˜¯å¦æˆåŠŸï¼Œè¿™é‡Œéƒ½ç»§ç»­è¯»ï¼Œä½œä¸ºå¤‡ç”¨)
    api_key_txt_path = Path("GOOGLE_CLOUD_API_KEY.txt")
    if api_key_txt_path.exists() and api_key_txt_path.is_file():
        try:
            key = api_key_txt_path.read_text(encoding="utf-8").strip()
            if key:
                os.environ["GOOGLE_CLOUD_API_KEY"] = key
                print(f"[INFO] å·²åŠ è½½ API Key: {api_key_txt_path.name}")
            else:
                print(f"[WARN] {api_key_txt_path} å†…å®¹ä¸ºç©ºã€‚")
        except Exception as e:
            print(f"[ERROR] è¯»å– API Key TXT å¤±è´¥: {e}")

# ========== åŸºæœ¬é…ç½® ==========

DEFAULT_MODEL_OPTIONS = [
    "gemini-2.5-flash",          # æ–‡æœ¬/å¤šæ¨¡æ€è¾“å…¥ï¼Œæ–‡æœ¬è¾“å‡ºï¼ˆå®˜æ–¹ quickstart æ¨èï¼‰
    "gemini-3-pro-preview",      # 3 Pro è¯­è¨€æ¨¡å‹ï¼ˆå¤šæ¨¡æ€è¾“å…¥ï¼Œæ–‡æœ¬è¾“å‡ºï¼‰
    "gemini-3-pro-image-preview",# 3 Pro å›¾åƒç”Ÿæˆ
    "gemini-2.5-flash-image",    # 2.5 å›¾åƒç”Ÿæˆ
]


# ä¸ Vertex ç¤ºä¾‹ç±»ä¼¼çš„å®½é«˜æ¯” & å°ºå¯¸
ASPECT_RATIO_OPTIONS = [
    "1:1 æ­£æ–¹å½¢4096x4096",
    "2:3 ç…§ç‰‡3392x5056",
    "3:2 æ¨ªç‰ˆç…§ç‰‡5056x3392",    
    "3:4 ç«–ç‰ˆæµ·æŠ¥3584x4800",
    "4:3 ä¼ ç»Ÿæ¨ªç‰ˆ4800x3584",
    "4:5 è¯ä»¶ç…§3712x4608",
    "5:4 è€å±å¹•4608x3712",
    "9:16 äººåƒ3072x5504",
    "16:9 é£æ™¯5504x3072",
    "21:9 è¶…å®½å±6336x2688"
    ]
# ç”µå½±çº§å®½å± 
# """
# 1:1       1024x1024	1210	2048x2048	1210	4096x4096	2000
# 2:3	    848x1264	1210	1696x2528	1210	3392x5056	2000
# 3:2	    1264x848	1210	2528x1696	1210	5056x3392	2000
# 3:4	    896x1200	1210	1792x2400	1210	3584x4800	2000
# 4:3	    1200x896	1210	2400x1792	1210	4800x3584	2000
# 4:5	    928x1152	1210	1856x2304	1210	3712x4608	2000
# 5:4	    1152x928	1210	2304x1856	1210	4608x3712	2000
# 9:16      768x1376	1210	1536x2752	1210	3072x5504	2000
# 16:9	    1376x768	1210	2752x1536	1210	5504x3072	2000
# 21:9	    1584x672	1210	3168x1344	1210	6336x2688	2000
# """


IMAGE_SIZE_OPTIONS = [
    "1K",
    "2K",
    "4K",
]

DEFAULT_ADVANCED_CONFIG: Dict[str, Any] = {
    "temperature": 0.9,
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 8192,
    "system_instruction": "",
}


# ========== å·¥å…·å‡½æ•°ï¼šclient & å‚æ•°æ„é€  ==========
def create_client(explicit_key: str | None = None, project: str | None = None, location: str = "global") -> genai.Client:
    """
    åˆ›å»º Clientã€‚
    ç­–ç•¥ï¼šä¼˜å…ˆå°è¯• Vertex AI (Project ID) -> å¤±è´¥åˆ™é™çº§åˆ° AI Studio (API Key)ã€‚
    """
    # è·å–ç¯å¢ƒä¸­çš„é…ç½®
    project_id = project or os.environ.get("GOOGLE_CLOUD_PROJECT")
    api_key = explicit_key or os.environ.get("GOOGLE_CLOUD_API_KEY")

    # === å°è¯• 1: Vertex AI ===
    if project_id:
        try:
            # print(f"[DEBUG] å°è¯•è¿æ¥ Vertex AI (Project: {project_id})...")
            return genai.Client(
                vertexai=True,
                project=project_id,
                location=location
            )
        except Exception as e:
            print(f"[WARN] Vertex AI Client åˆå§‹åŒ–å¤±è´¥ ({e})ï¼Œå°è¯•é™çº§åˆ° API Key æ¨¡å¼...")
    
    # === å°è¯• 2: API Key (AI Studio) ===
    # è·‘åˆ°è¿™é‡Œè¯´æ˜ï¼šè¦ä¹ˆæ²¡ Project IDï¼Œè¦ä¹ˆ Vertex åˆå§‹åŒ–æŒ‚äº† 
    if api_key:
        print("[INFO] ä½¿ç”¨ API Key æ¨¡å¼ (AI Studio)")
        return genai.Client(
            vertexai=False,
            api_key=api_key
        )
    
    # === å½»åº•å¤±è´¥ ===
    raise RuntimeError(
        "âŒ æ— æ³•åˆ›å»º Clientï¼šæ—¢æ²¡æœ‰æœ‰æ•ˆçš„ Vertex Project IDï¼Œä¹Ÿæ²¡æœ‰å¯ç”¨çš„ API Keyã€‚\n"
        "è¯·æ£€æŸ¥æ ¹ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨ 'GOOGLE_CLOUD_API_KEY.json' æˆ– 'GOOGLE_CLOUD_API_KEY.txt'ã€‚"
    )
    
def ui_aspect_to_vertex(value: str) -> str:
    """
    å°† UI æ˜¾ç¤ºçš„ '1:1 (Square)' è½¬æˆ Vertex æ¥å—çš„ '1:1'
    """
    if not value:
        return "1:1"
    if value.startswith("1:1"):
        return "1:1"
    if value.startswith("3:2"):
        return "3:2"
    if value.startswith("2:3"):
        return "2:3"
    if value.startswith("3:4"):
        return "3:4"
    if value.startswith("4:3"):
        return "4:3"
    if value.startswith("4:5"):
        return "4:5"
    if value.startswith("5:4"):
        return "5:4"
    if value.startswith("16:9"):
        return "16:9"
    if value.startswith("9:16"):
        return "9:16"
    if value.startswith("21:9"):
        return "21:9"
    return "1:1"


def build_generate_config(
    temperature: float,
    top_p: float,
    top_k: int,
    max_output_tokens: int,
    aspect_ratio_ui: str,
    image_size_ui: str,
    want_image: bool,
    want_thinking: bool,
    want_search: bool,
) -> types.GenerateContentConfig:
    """
    æ„é€  GenerateContentConfigã€‚

    - æ–‡æœ¬æ¨¡å‹ï¼šåªè®¾ç½®é‡‡æ ·å‚æ•° + å…³æ‰å®‰å…¨è¿‡æ»¤
    - å›¾åƒæ¨¡å‹ï¼šåŠ ä¸Š response_modalities + ImageConfig(aspect_ratio, image_size)
    - æ€è€ƒæ¨¡å‹ï¼šå°è¯•åŠ ä¸Š ThinkingConfig(thinking_level="HIGH")ï¼Œå¦‚æœ SDK ä¸æ”¯æŒä¼šè‡ªåŠ¨å¿½ç•¥
    """
    safety_settings = [
        types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="OFF"),
        types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="OFF"),
        types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="OFF"),
        types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="OFF"),
    ]

    cfg_kwargs: Dict[str, Any] = dict(
        temperature=temperature,
        top_p=top_p,
        top_k=top_k,
        max_output_tokens=max_output_tokens,
        safety_settings=safety_settings,
    )
    # === Google Search / Grounding ===
    if want_search:
        cfg_kwargs["tools"] = [{"google_search": {}}]

    # === å›¾åƒæ¨¡å‹ï¼šå‚è€ƒ Nano-Banana Pro ç¤ºä¾‹ï¼Œå¸¦ä¸Š aspect_ratio + image_size ===
    if want_image:
        aspect_ratio = ui_aspect_to_vertex(aspect_ratio_ui)
        image_size = image_size_ui or "1K"
        
        # --- æ–°å¢ï¼šäººç‰©ç”Ÿæˆå‚æ•° ---
        # "allow_all" = Allow (All ages)
        # "allow_adult" = Allow (Adults only)
        # "dont_allow" = Don't allow
        person_generation = "allow_all" 

        try:
            img_cfg = types.ImageConfig(
                aspect_ratio=aspect_ratio,
                image_size=image_size,
                # person_generation=person_generation, # <--- åŠ ä¸Šè¿™ä¸€è¡Œï¼
            )
        except Exception as e:
            print(f"[WARN] å½“å‰ ImageConfig ä¸æ”¯æŒé«˜çº§å‚æ•°ï¼Œé€€å›åŸºç¡€é…ç½®ï¼š{e}")
            img_cfg = types.ImageConfig(aspect_ratio=aspect_ratio)

        cfg_kwargs["response_modalities"] = ["TEXT", "IMAGE"]
        cfg_kwargs["image_config"] = img_cfg

    # === æ€è€ƒæ¨¡å‹ï¼šå°è¯•åŠ ä¸Š thinking_config ===
    if want_thinking:
        try:
            # ä¿®æ”¹ï¼šå»æ‰ä¸æ”¯æŒçš„ thinking_level å‚æ•°ï¼Œåªå®ä¾‹åŒ–å¯¹è±¡
            # å¦‚æœæ–°ç‰ˆ SDK éœ€è¦ include_thoughts=Trueï¼Œé€šå¸¸æ˜¯åœ¨ generate_content çš„è°ƒç”¨é‡Œï¼Œè€Œä¸æ˜¯ Config é‡Œ
            # è¿™é‡Œå…ˆè®¾ä¸ºç©ºé…ç½®ï¼Œæˆ–è€…æ ¹æ®ä½ çš„ SDK ç‰ˆæœ¬æŸ¥é˜…æ–‡æ¡£ã€‚
            # ä¸ºäº†é˜²æ­¢æŠ¥é”™ï¼Œæˆ‘ä»¬å…ˆä¼ å…¥ä¸€ä¸ªç©ºå­—å…¸æˆ–æœ€åŸºç¡€çš„é…ç½®
            thinking_cfg = types.ThinkingConfig(include_thoughts=True) 
            cfg_kwargs["thinking_config"] = thinking_cfg
        except Exception as e:
            print(f"[WARN] ThinkingConfig é…ç½®å‡ºé”™ï¼Œå·²å¿½ç•¥ï¼š{e}")

    return types.GenerateContentConfig(**cfg_kwargs)


def file_to_image_part(path: str) -> types.Part:
    """
    å°†æœ¬åœ°æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸º Partï¼Œç”¨äºå›¾ç‰‡è¾“å…¥ã€‚
    ç±»ä¼¼ Vertex ç¤ºä¾‹é‡Œçš„ Part.from_uriï¼Œåªæ˜¯æˆ‘ä»¬è¿™é‡Œæ˜¯æœ¬åœ°æ–‡ä»¶ã€‚
    """
    mime, _ = mimetypes.guess_type(path)
    if not mime:
        # é»˜è®¤ png
        mime = "image/png"
    with open(path, "rb") as f:
        data = f.read()
    return types.Part.from_bytes(data=data, mime_type=mime)

def _save_as_jpg_under_1mb(src_path: str, dst_path: str, max_bytes: int = 1024 * 1024) -> None:
    """
    æŠŠ src_path è½¬æˆ JPG ä¿å­˜åˆ° dst_pathï¼Œå¹¶å°½é‡ä¿è¯æ–‡ä»¶ <= max_bytesï¼ˆé»˜è®¤ 1MBï¼‰ã€‚
    """
    img = Image.open(src_path)
    if img.mode in ("RGBA", "P"):
        img = img.convert("RGB")
    else:
        img = img.convert("RGB")

    os.makedirs(os.path.dirname(dst_path), exist_ok=True)

    # å…ˆè°ƒè´¨é‡ï¼›ä¸è¡Œå†ç¼©æ”¾
    quality = 92
    width, height = img.size

    while True:
        img.save(dst_path, format="JPEG", quality=quality, optimize=True)
        if os.path.getsize(dst_path) <= max_bytes:
            return

        quality -= 8
        if quality >= 40:
            continue

        # quality å·²ç»å¾ˆä½äº†ï¼Œå¼€å§‹ç¼©æ”¾
        scale = 0.85
        new_w = max(256, int(width * scale))
        new_h = max(256, int(height * scale))
        if new_w == width and new_h == height:
            # å·²ç»ç¼©ä¸åŠ¨äº†ï¼Œç›´æ¥ä¿å­˜ï¼ˆå¯èƒ½ç•¥è¶… 1MBï¼‰
            img.save(dst_path, format="JPEG", quality=40, optimize=True)
            return

        img = img.resize((new_w, new_h))
        width, height = img.size
        quality = 88

def _ensure_export_session_dir(out_dir: str = "exports", base_name: str = "chat_session") -> str:
    os.makedirs(out_dir, exist_ok=True)
    sid = f"{base_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}"
    session_dir = os.path.join(out_dir, sid)
    os.makedirs(os.path.join(session_dir, "images"), exist_ok=True)
    md_path = os.path.join(session_dir, "chat.md")
    if not os.path.exists(md_path):
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(f"# Chat Log\n\n- Session: {sid}\n- Created: {datetime.now().isoformat(timespec='seconds')}\n")
    return session_dir

def _append_md(md_path: str, text: str) -> None:
    with open(md_path, "a", encoding="utf-8") as f:
        f.write(text if text.endswith("\n") else text + "\n")

def log_turn_to_md(
    session_dir: str,
    user_text: str,
    user_image_paths: list[str],
    assistant_text: str,
    assistant_image_paths: list[str],
) -> str:
    """
    è¿½åŠ è®°å½•ä¸€è½®å¯¹è¯åˆ° exports/<session>/chat.md
    å›¾ç‰‡ä¼šè¢«è½¬æ¢æˆ <=1MB jpgï¼Œä¿å­˜åˆ° images/ ä¸‹ã€‚
    è¿”å› session_dirï¼ˆç”¨äº state ä¿æŒï¼‰ã€‚
    """
    if not session_dir:
        session_dir = _ensure_export_session_dir()

    images_dir = os.path.join(session_dir, "images")
    md_path = os.path.join(session_dir, "chat.md")

    def _conv_many(paths: list[str], prefix: str) -> list[str]:
        rels = []
        for p in (paths or []):
            if not p or not os.path.exists(p):
                continue
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            name = f"{datetime.now().strftime('%H%M%S')}_{uuid.uuid4().hex[:6]}_{prefix}.jpg"
            dst_abs = os.path.join(images_dir, name)
            _save_as_jpg_under_1mb(p, dst_abs, max_bytes=1024 * 1024)
            rels.append(f"images/{name}")
        return rels

    user_imgs_rel = _conv_many(user_image_paths, "u")
    asst_imgs_rel = _conv_many(assistant_image_paths, "a")

    ts = datetime.now().isoformat(timespec="seconds")
    block = []
    block.append("\n---\n")
    block.append(f"## Turn @ {ts}\n")

    block.append("### User\n")
    if user_text:
        block.append(user_text.strip() + "\n")
    for rel in user_imgs_rel:
        block.append(f"\n![]({rel})\n")

    block.append("\n### Assistant\n")
    if assistant_text:
        block.append(assistant_text.strip() + "\n")
    for rel in asst_imgs_rel:
        block.append(f"\n![]({rel})\n")

    _append_md(md_path, "\n".join(block))
    return session_dir

def export_chat_to_md(
    history: List[dict],
    out_base_name: str = "chat_export",
    out_dir: str = "exports",
) -> str:
    """
    å¯¼å‡ºå½“å‰ Chatbot(history type="messages") ä¸º Markdownã€‚
    å¦‚æœå†…å®¹é‡Œå¼•ç”¨äº†å›¾ç‰‡è·¯å¾„ï¼šæŠŠå®ƒä»¬è½¬ä¸º <=1MB çš„ jpgï¼Œæ”¾åˆ° exports/<name>/images/ ä¸‹ï¼Œå¹¶æ›¿æ¢ md å¼•ç”¨ã€‚
    è¿”å›å¯¼å‡ºçš„ md æ–‡ä»¶è·¯å¾„ã€‚
    """
    safe_name = (out_base_name or "chat_export").strip() or "chat_export"
    safe_name = re.sub(r"[^a-zA-Z0-9_\-]+", "_", safe_name)

    export_root = os.path.join(out_dir, safe_name)
    images_dir = os.path.join(export_root, "images")
    os.makedirs(images_dir, exist_ok=True)

    # åŒ¹é… markdown å›¾ç‰‡ï¼š![alt](path)
    img_pat = re.compile(r"!\[[^\]]*\]\(([^)]+)\)")

    used_map = {}  # src_path -> new_rel_path
    img_counter = 0

    def _convert_one(src: str) -> str:
        nonlocal img_counter
        src_norm = src.strip().strip('"').strip("'")
        src_norm = src_norm.replace("\\", "/")
        if src_norm in used_map:
            return used_map[src_norm]

        if not os.path.exists(src_norm):
            # æ‰¾ä¸åˆ°å°±åŸæ ·è¿”å›
            return src

        img_counter += 1
        dst_name = f"{img_counter}.jpg"
        dst_abs = os.path.join(images_dir, dst_name)
        _save_as_jpg_under_1mb(src_norm, dst_abs, max_bytes=1024 * 1024)

        rel = f"images/{dst_name}"
        used_map[src_norm] = rel
        return rel

    lines = []
    lines.append(f"# Chat Export\n\n- Exported: {datetime.now().isoformat(timespec='seconds')}\n")

    for msg in (history or []):
        role = msg.get("role", "unknown")
        content = msg.get("content", "")

        # æ›¿æ¢å›¾ç‰‡å¼•ç”¨ä¸ºå¯¼å‡ºç›®å½•ä¸‹çš„ images/xxx.jpg
        def _repl(m):
            path = m.group(1)
            new_rel = _convert_one(path)
            return m.group(0).replace(path, new_rel)

        content2 = img_pat.sub(_repl, content)

        if role == "user":
            lines.append("\n## User\n")
        elif role == "assistant":
            lines.append("\n## Assistant\n")
        else:
            lines.append(f"\n## {role}\n")

        lines.append(content2.strip() + "\n")

    md_path = os.path.join(export_root, f"{safe_name}.md")
    with open(md_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))

    return md_path


# ========== ä¸»ä¸šåŠ¡é€»è¾‘ï¼šè°ƒç”¨ Geminiï¼ˆVertex AIï¼‰ ==========
def call_gemini_vertex(
    api_key: str,
    model_name: str,
    history_messages: List[Dict[str, Any]],
    user_text: str,
    user_images: List[str],
    aspect_ratio: str,
    image_size: str,
    system_instruction: str,
    temperature: float,
    top_p: float,
    top_k: int,
    max_output_tokens: int,
    enable_search: bool,
) -> Tuple[str, List[str]]:  # <--- ä¿®æ”¹è¿”å›å€¼ç±»å‹æç¤º
    """
    ä¿®æ”¹åï¼šè¿”å› (æ–‡æœ¬å†…å®¹, ç”Ÿæˆçš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨)
    """
    # 1) åˆ›å»º client (ç¡®ä¿ location="global")
    # å¦‚æœä½ çš„ create_client è¿˜æ²¡æ”¹é»˜è®¤å€¼ï¼Œå»ºè®®è¿™é‡Œå¼ºè¡Œä¼  global
    client = create_client(api_key, location="global") 

    # 2) ç»„è£… contents (ä¿æŒä¸å˜)
    contents: List[types.Content] = []
    
    # ... (ä¸­é—´ç»„è£… contents çš„ä»£ç å®Œå…¨ä¿æŒä¸å˜ï¼Œçœç•¥ä»¥èŠ‚çœç¯‡å¹…) ...
    if system_instruction.strip():
        contents.append(types.Content(role="system", parts=[types.Part.from_text(text=system_instruction.strip())]))
    for msg in history_messages:
        # ... (ä¿æŒåŸæ ·) ...
        parts = []
        if msg.get("text"): parts.append(types.Part.from_text(text=msg.get("text")))
        for img in msg.get("images", []):
            try: parts.append(file_to_image_part(img))
            except: continue
        if parts: contents.append(types.Content(role="user" if msg.get("role")=="user" else "model", parts=parts))
    
    current_parts = []
    if user_text: current_parts.append(types.Part.from_text(text=user_text))
    for img in user_images:
        try: current_parts.append(file_to_image_part(img))
        except: continue
    if current_parts: contents.append(types.Content(role="user", parts=current_parts))

    # 3) æ„é€  Config (ä¿æŒä¸å˜)
    # è®°å¾—ä½ ä¹‹å‰ç”¨çš„å­—å…¸ç»•è¿‡æ ¡éªŒçš„æ–¹æ³•ï¼Œæˆ–è€…ç¡®ä¿ build_generate_config æ˜¯æœ€æ–°çš„
    image_models = {"gemini-2.5-flash-image", "gemini-3-pro-image-preview"}
    want_image = model_name in image_models
    want_thinking = model_name == "gemini-3-pro-preview"

    generate_config = build_generate_config(
        temperature=temperature, top_p=top_p, top_k=top_k, max_output_tokens=max_output_tokens,
        aspect_ratio_ui=aspect_ratio, image_size_ui=image_size,
        want_image=want_image, want_thinking=want_thinking,
        want_search=bool(enable_search),
    )
    
    _debug_print_send(
        model_name=model_name,
        system_instruction=system_instruction,
        user_text=user_text,
        image_files=user_images,
        generate_config=generate_config,
    )

# 4) è°ƒç”¨
    try:
        response = client.models.generate_content(
            model=model_name,
            contents=contents if len(contents) > 1 else (contents[0] if contents else user_text),
            config=generate_config,
        )
    except Exception as e:
        raise RuntimeError(f"è°ƒç”¨ Vertex Gemini å¤±è´¥ï¼š{e}")

    # 5) è§£æç»“æœ (ğŸ› ï¸ å¢å¼ºè°ƒè¯•ç‰ˆ)
    _debug_print_recv(response) # æ‰“å°å“åº”

    text_chunks = []
    generated_images = []

    # å…ˆæ£€æŸ¥æœ‰æ²¡æœ‰ candidates
    if not hasattr(response, "candidates") or not response.candidates:
        # è¿™ç§æƒ…å†µé€šå¸¸æ˜¯ prompt_feedback ç›´æ¥æ‹¦æˆªäº†
        feedback = getattr(response, "prompt_feedback", "æ— åé¦ˆä¿¡æ¯")
        return f"âš ï¸ æ¨¡å‹æœªè¿”å›ä»»ä½•å€™é€‰ç»“æœ (Blocked)ã€‚\nåé¦ˆä¿¡æ¯: {feedback}", []

    first_candidate = response.candidates[0]
    finish_reason = getattr(first_candidate, "finish_reason", "UNKNOWN")

    # æå–æ–‡æœ¬
    if getattr(response, "text", None):
        text_chunks.append(response.text)

    # æå– Parts (æ–‡æœ¬å’Œå›¾ç‰‡)
    from pathlib import Path
    import time

    for part in getattr(response, "parts", []) or []:
        if getattr(part, "thought", None): continue
        if getattr(part, "text", None):
            text_chunks.append(part.text)
            continue
        
        # å¤„ç†å›¾ç‰‡
        as_image = getattr(part, "as_image", None)
        if callable(as_image):
            img = as_image()
            if img is not None:
                out_dir = Path("outputs")
                out_dir.mkdir(exist_ok=True)
                filename = f"{model_name}_{int(time.time()*1000)}.png"
                out_path = out_dir / filename
                try:
                    img.save(out_path)
                    generated_images.append(str(out_path))
                except Exception:
                    pass

    final_text = "\n".join(t.strip() for t in text_chunks if t.strip())
    
    # ğŸ› ï¸ å…³é”®ä¿®æ”¹ï¼šå¦‚æœä»€ä¹ˆéƒ½æ²¡æ‹¿åˆ°ï¼Œæ£€æŸ¥ Finish Reason
    if not final_text and not generated_images:
        # å¦‚æœæ˜¯å› ä¸ºå®‰å…¨åŸå› è¢«æ‹¦æˆª
        if "SAFETY" in str(finish_reason):
            return f"ğŸ›¡ï¸ å†…å®¹è¢«å®‰å…¨ç­–ç•¥æ‹¦æˆª (Finish Reason: {finish_reason})ã€‚\nè¯·å°è¯•ä¿®æ”¹æç¤ºè¯æˆ–å›¾ç‰‡ã€‚", []
        # å¦‚æœæ˜¯å…¶ä»–åŸå› 
        elif finish_reason != "STOP":
             return f"âš ï¸ æ¨¡å‹åœæ­¢ç”Ÿæˆï¼Œä½†æœªè¿”å›å†…å®¹ (Finish Reason: {finish_reason})ã€‚\nè¿™é€šå¸¸æ˜¯å› ä¸ºè¾“å…¥äº†ä¸¤å¼ å›¾ä½†æ²¡æœ‰æä¾›è¶³å¤Ÿçš„æ–‡å­—æŒ‡ä»¤ï¼Œæˆ–è€…æ¨¡å‹å¯¹å¤šå›¾è¾“å…¥æ„Ÿåˆ°å›°æƒ‘ã€‚", []
        else:
             return "âš ï¸ API è¿”å›æˆåŠŸ (STOP)ï¼Œä½†å†…å®¹ä¸ºç©ºã€‚è¿™å¯èƒ½æ˜¯ Vertex AI çš„ä¸´æ—¶æ•…éšœæˆ–æ¨¡å‹è¾“å‡ºäº†ç©ºå­—ç¬¦ä¸²ã€‚", []

    # å¦‚æœåªæœ‰å›¾æ²¡æœ‰å­—ï¼Œç»™ä¸ªæç¤º
    if not final_text and generated_images:
        final_text = "âœ… å›¾åƒå·²ç”Ÿæˆï¼ˆè§ä¸‹æ–¹ï¼‰"
    
    return final_text, generated_images

# ========== Gradio äº¤äº’é€»è¾‘ ==========
def gr_chat_send(
    user_input: str,
    image_files: List[str],
    history: List[dict],
    raw_messages: List[Dict[str, Any]],
    api_key: str, 
    model_name: str,
    aspect_ratio: str, image_size: str, temperature: float, top_p: float, top_k: int, max_output_tokens: int, system_instruction: str,
    enable_search: bool,
    session_dir,
):
    user_input = (user_input or "").strip()
    image_files = image_files or []

    if not user_input and not image_files:
        return history, raw_messages, "", None, session_dir

    # ===== 1. ç”¨æˆ·æ¶ˆæ¯ä¸Šå± (æ ¸å¿ƒä¿®æ”¹) =====
    # ç­–ç•¥ï¼šä¸å†æ„å»º {"type": "image"} å­—å…¸ï¼Œè€Œæ˜¯æŠŠå›¾ç‰‡è½¬ä¸º Markdown æ–‡æœ¬
    # è¿™æ ·å®Œå…¨é¿å¼€äº† Gradio 5.9.1 çš„ Pydantic æ ¡éªŒ Bug
    
    user_display_content = user_input
    if image_files:
        # ğŸ› ï¸ ä¿®å¤ç‚¹ 1ï¼šæŠŠè·¯å¾„ä¸­çš„åæ–œæ  \ æ›¿æ¢ä¸º /
        img_markdowns = [f"\n![image]({str(path).replace(os.sep, '/')})" for path in image_files]
        user_display_content += "\n" + "\n".join(img_markdowns)    
    
    # æ„å»ºä¸ºçº¯æ–‡æœ¬æ¶ˆæ¯ (Gradio ä¼šè‡ªåŠ¨æ¸²æŸ“ Markdown ä¸­çš„å›¾ç‰‡)
    history = history or []
    history.append({
        "role": "user",
        "content": user_display_content 
    })

    # ===== 2. è®°å½•åŸå§‹æ¶ˆæ¯ (ä¼ ç»™ API ç”¨ï¼Œä¿æŒåŸæ ·) =====
    # è¿™é‡Œä¾ç„¶ä¿ç•™ structured æ ¼å¼ï¼Œå› ä¸º Gemini API éœ€è¦åŒºåˆ† text å’Œ image
    raw_messages.append({"role": "user", "text": user_input, "images": image_files.copy()})
    
    # ===== 3. è°ƒç”¨ API =====
    try:
        reply_text, generated_images = call_gemini_vertex(
            api_key=api_key, model_name=model_name,
            history_messages=raw_messages[:-1],
            user_text=user_input, user_images=image_files,
            aspect_ratio=aspect_ratio, image_size=image_size,
            system_instruction=system_instruction,
            temperature=float(temperature), top_p=float(top_p), top_k=int(top_k), max_output_tokens=int(max_output_tokens),
            enable_search=bool(enable_search),
        )
    except Exception as e:
        import traceback
        traceback.print_exc()
        reply_text = f"âŒ å‡ºé”™ï¼š{e}"
        generated_images = []

    # ===== 4. æ„å»ºåŠ©æ‰‹æ¶ˆæ¯ (åŒæ ·ä½¿ç”¨ Markdown ä¿®å¤) =====
    
    display_text = f"**[{model_name}]**\n{reply_text}" if reply_text else f"**[{model_name}]**"
    
    if generated_images:
        # ğŸ› ï¸ ä¿®å¤ç‚¹ 2ï¼šåŒæ ·æ›¿æ¢åæ–œæ 
        gen_img_markdowns = [f"\n![generated]({str(path).replace(os.sep, '/')})" for path in generated_images]
        display_text += "\n" + "\n".join(gen_img_markdowns)
    
    # åŠ©æ‰‹æ¶ˆæ¯ä¹Ÿä½œä¸ºçº¯æ–‡æœ¬æ¨å…¥å†å²
    history.append({
        "role": "assistant",
        "content": display_text,
    })
    
    session_dir_new = log_turn_to_md(
        session_dir,                 # æ¥è‡ª gr.State
        user_text=user_input,
        user_image_paths=image_files,
        assistant_text=reply_text,
        assistant_image_paths=generated_images or [],
    )
    
    # ===== 5. è®°å½•åŸå§‹åŠ©æ‰‹æ¶ˆæ¯ =====
    # åŸå§‹è®°å½• (æ— å›¾ï¼Œå› ä¸ºæˆ‘ä»¬ä¸æŠŠç”Ÿæˆå›¾ä½œä¸ºä¸‹ä¸€è½®è¾“å…¥)
    raw_messages.append({
        "role": "model",
        "text": reply_text,
        "images": [], 
    })

    return history, raw_messages, "", None, session_dir_new

def gr_clear(history, raw_messages):
    return [], []

# ========== æ­å»º Gradio UI ==========

def create_gradio_app() -> gr.Blocks:
    # å…ˆä» config.json è¯»å–é¢„è®¾
    presets = load_presets_from_config()
    if presets:
        first_key = next(iter(presets.keys()))
        p0 = presets[first_key]
        default_model = p0.get("model_name", DEFAULT_MODEL_OPTIONS[0])
        default_aspect = p0.get("aspect_ratio", ASPECT_RATIO_OPTIONS[0])
        default_image_size = p0.get("image_size", IMAGE_SIZE_OPTIONS[0])
        default_temp = p0.get("temperature", DEFAULT_ADVANCED_CONFIG["temperature"])
        default_top_p = p0.get("top_p", DEFAULT_ADVANCED_CONFIG["top_p"])
        default_top_k = p0.get("top_k", DEFAULT_ADVANCED_CONFIG["top_k"])
        default_max_tokens = p0.get("max_output_tokens", DEFAULT_ADVANCED_CONFIG["max_output_tokens"])
        default_sys_inst = p0.get("system_instruction", DEFAULT_ADVANCED_CONFIG["system_instruction"])
    else:
        first_key = None
        default_model = DEFAULT_MODEL_OPTIONS[0]
        default_aspect = ASPECT_RATIO_OPTIONS[0]
        default_image_size = IMAGE_SIZE_OPTIONS[0]
        default_temp = DEFAULT_ADVANCED_CONFIG["temperature"]
        default_top_p = DEFAULT_ADVANCED_CONFIG["top_p"]
        default_top_k = DEFAULT_ADVANCED_CONFIG["top_k"]
        default_max_tokens = DEFAULT_ADVANCED_CONFIG["max_output_tokens"]
        default_sys_inst = DEFAULT_ADVANCED_CONFIG["system_instruction"]

    with gr.Blocks(title="Banana Studio (Vertex AI / google.genai)") as demo:
        gr.Markdown(
            "# ğŸŒ Banana Studio - Vertex AI ç‰ˆ\n"
            "ä½¿ç”¨ `google.genai` è°ƒç”¨ Geminiï¼ˆVertex AI ç«¯ç‚¹ï¼‰ï¼Œå®‰å…¨è¿‡æ»¤å…¨éƒ¨å…³é—­ï¼ˆOFFï¼Œä»…ç”¨äºæµ‹è¯•ï¼‰ã€‚"
        )
        # 1. åˆ›å»ºé¡¶çº§ Tabs å®¹å™¨
        with gr.Tabs():
            
            # === Tab 1: ä¸»å¯¹è¯ç•Œé¢ (åŸæ¥çš„ç•Œé¢) ===
            with gr.Tab("ğŸŒ Banana Studio"):
                raw_messages_state = gr.State([])  # ä¿å­˜åŸå§‹ç»“æ„ [{'role', 'text', 'images'}, ...]
                export_session_dir = gr.State(value="")

                with gr.Row():
                    # ===== å·¦ä¾§ï¼šå‚æ•°åŒº =====
                    with gr.Column(scale=1, min_width=320):
                        gr.Markdown("### âš™ï¸ è®¾ç½®é¢æ¿")

                        api_key = gr.Textbox(
                            label="GOOGLE_CLOUD_API_KEYï¼ˆç•™ç©ºåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰",
                            value=os.environ.get("GOOGLE_CLOUD_API_KEY", ""),
                            type="password",
                        )

                        model_name = gr.Dropdown(
                            label="æ¨¡å‹",
                            choices=DEFAULT_MODEL_OPTIONS,
                            value=default_model,
                        )
                        
                        enable_search = gr.Checkbox(
                            label="å¯ç”¨ Google Searchï¼ˆGrounding / è”ç½‘æ£€ç´¢ï¼‰",
                            value=False,
                        )

                        aspect_ratio = gr.Dropdown(
                            label="å›¾åƒå®½é«˜æ¯”ï¼ˆç”¨äº image_configï¼Œä»…å½“å‰ç¤ºä¾‹ä¸­ä¼ ç»™é…ç½®ï¼‰",
                            choices=ASPECT_RATIO_OPTIONS,
                            value=default_aspect,
                        )

                        image_size = gr.Dropdown(
                            label="å›¾åƒå°ºå¯¸ï¼ˆimage_sizeï¼Œä¾‹å¦‚ 1K / 512 / 2Kï¼‰",
                            choices=IMAGE_SIZE_OPTIONS,
                            value=default_image_size,
                        )

                        gr.Markdown("#### é«˜çº§å‚æ•°")

                        temperature = gr.Slider(
                            label="temperature",
                            minimum=0.0,
                            maximum=2.0,
                            value=default_temp,
                            step=0.05,
                        )
                        top_p = gr.Slider(
                            label="top_p",
                            minimum=0.0,
                            maximum=1.0,
                            value=default_top_p,
                            step=0.01,
                        )
                        top_k = gr.Slider(
                            label="top_k",
                            minimum=1,
                            maximum=100,
                            value=default_top_k,
                            step=1,
                        )
                        max_output_tokens = gr.Slider(
                            label="max_output_tokens",
                            minimum=256,
                            maximum=32768,
                            value=default_max_tokens,
                            step=256,
                        )

                        system_instruction = gr.Textbox(
                            label="System Instructionï¼ˆç³»ç»Ÿæç¤ºè¯ï¼‰",
                            lines=4,
                            value=default_sys_inst,
                            placeholder="åœ¨è¿™é‡Œå†™å¯¹æ¨¡å‹çš„æ€»æŒ‡å¯¼ï¼Œæ¯”å¦‚ï¼šä½ æ˜¯ä¸€ä¸ªå–„äºå†™ä»£ç å’ŒæŸ¥ bug çš„åŠ©æ‰‹â€¦â€¦",
                        )

                        gr.Markdown("#### å‚æ•°é¢„è®¾é…ç½®")

                        # çŠ¶æ€ï¼šæ‰€æœ‰é¢„è®¾
                        presets_state = gr.State(presets)

                        preset_name_input = gr.Textbox(
                            label="é¢„è®¾åç§°",
                            placeholder="ä¾‹å¦‚ï¼šé»˜è®¤ / ç¿»è¯‘-ä¿å®ˆ / åˆ›ä½œ-å¤§èƒ†",
                            value=first_key or "",
                        )

                        preset_dropdown = gr.Dropdown(
                            label="å·²ä¿å­˜é¢„è®¾",
                            choices=list(presets.keys()),
                            value=first_key,
                        )

                        with gr.Row():
                            btn_save_preset = gr.Button("ğŸ’¾ ä¿å­˜å½“å‰ä¸ºé¢„è®¾")
                            btn_load_preset = gr.Button("ğŸ“¥ åŠ è½½é¢„è®¾")
                            btn_delete_preset = gr.Button("ğŸ—‘ åˆ é™¤é¢„è®¾")

                        # --- é¢„è®¾æŒ‰é’®ç»‘å®š ---
                        btn_save_preset.click(
                            fn=save_preset,
                            inputs=[
                                preset_name_input,
                                presets_state,
                                model_name,
                                aspect_ratio,
                                image_size,
                                temperature,
                                top_p,
                                top_k,
                                max_output_tokens,
                                system_instruction,
                            ],
                            outputs=[
                                presets_state,
                                preset_dropdown,
                            ],
                        )

                        btn_load_preset.click(
                            fn=load_preset,
                            inputs=[
                                preset_dropdown,
                                presets_state,
                            ],
                            outputs=[
                                model_name,
                                aspect_ratio,
                                image_size,
                                temperature,
                                top_p,
                                top_k,
                                max_output_tokens,
                                system_instruction,
                            ],
                        )

                        btn_delete_preset.click(
                            fn=delete_preset,
                            inputs=[
                                preset_dropdown,
                                presets_state,
                            ],
                            outputs=[
                                presets_state,
                                preset_dropdown,
                            ],
                        )

                        gr.Markdown(
                            "> ğŸ” å½“å‰ç¤ºä¾‹ä¸­ï¼Œæ‰€æœ‰ SafetySetting çš„ threshold å‡ä¸º `OFF`ï¼Œ"
                            "ä»…å»ºè®®åœ¨æœ¬åœ°/å¼€å‘ç¯å¢ƒä¸­ä½¿ç”¨ã€‚"
                        )

                    # ===== å³ä¾§ï¼šå¯¹è¯åŒº =====
                    with gr.Column(scale=2):
                        gr.Markdown("### ğŸ’¬ å¯¹è¯åŒº")

                        chatbot = gr.Chatbot(
                            label="Chat",
                            height=520,
                            type="messages",  
                        )

                        with gr.Row():
                            user_input = gr.Textbox(
                                label="è¾“å…¥æ¶ˆæ¯",
                                placeholder="åœ¨è¿™é‡Œè¾“å…¥é—®é¢˜æˆ–æè¿°â€¦",
                                scale=4,
                            )
                        image_upload = gr.Files(
                            label="ä¸Šä¼ å›¾ç‰‡ï¼ˆå¤šå¼ å›¾å°†ä½œä¸ºå½“å‰è½®å¤šæ¨¡æ€è¾“å…¥ï¼‰",
                            file_types=["image"],
                            file_count="multiple",
                        )

                        with gr.Row():
                            send_btn = gr.Button("å‘é€", variant="primary")
                            clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")

                        # ç»‘å®šå‘é€äº‹ä»¶
                        send_btn.click(
                            fn=gr_chat_send,
                            inputs=[
                                user_input,
                                image_upload,
                                chatbot,
                                raw_messages_state,
                                api_key,
                                model_name,
                                aspect_ratio,
                                image_size,
                                temperature,
                                top_p,
                                top_k,
                                max_output_tokens,
                                system_instruction,
                                enable_search,
                                export_session_dir,
                            ],
                            outputs=[
                                chatbot,
                                raw_messages_state,
                                user_input,
                                image_upload,
                                export_session_dir,
                            ],
                        )

                        clear_btn.click(
                            fn=gr_clear,
                            inputs=[chatbot, raw_messages_state],
                            outputs=[chatbot, raw_messages_state],
                        )
            
            # === Tab 2+: åŠ¨æ€åŠ è½½æ’ä»¶ ===
            # ç›´æ¥åœ¨è¿™é‡Œè°ƒç”¨åŠ è½½å‡½æ•°ï¼Œå®ƒä¼šåœ¨å½“å‰çš„ gr.Tabs() ä¸Šä¸‹æ–‡ä¸­è‡ªåŠ¨æ¸²æŸ“ Tab
            load_plugins_from_dir("plugins")

        return demo


if __name__ == "__main__":
    # â‘  åŠ è½½ Key
    load_google_api_key_from_file()

    # â‘¡ åˆ›å»º UI
    demo = create_gradio_app()
    
    # æŸ¥æ‰¾ç«¯å£
    port = find_free_port(7860, 7880, host="127.0.0.1")

    # â‘¢ å¯åŠ¨ (ğŸ› ï¸ ä¿®å¤ç‚¹ï¼šæ·»åŠ  allowed_paths)
    # å…è®¸ Gradio è¯»å–å½“å‰ç›®å½•ä¸‹çš„ outputs æ–‡ä»¶å¤¹å’Œæ ¹ç›®å½•æ–‡ä»¶
    demo.launch(
        server_name="127.0.0.1", 
        server_port=port,
        allowed_paths=[".", "outputs"] 
    )
    print(f"[banana] Gradio running on http://127.0.0.1:{port}")

