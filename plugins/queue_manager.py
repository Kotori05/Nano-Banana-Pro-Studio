import gradio as gr
import time
import random
import json
import traceback
from datetime import datetime

# å°è¯•ä»ä¸»ç¨‹åºå¯¼å…¥æ ¸å¿ƒè°ƒç”¨å‡½æ•°å’Œé…ç½®
# æ³¨æ„ï¼šä¸ºäº†é¿å…å¾ªç¯å¯¼å…¥ï¼Œå»ºè®®åœ¨å‡½æ•°å†…éƒ¨å¯¼å…¥ï¼Œæˆ–è€…ç¡®ä¿ nano-banana--pro.py ç»“æ„å…è®¸
try:
    from nano-banana-pro import call_gemini_vertex, DEFAULT_MODEL_OPTIONS
except ImportError:
    # å¦‚æœç‹¬ç«‹è¿è¡Œæˆ–å¯¼å…¥å¤±è´¥çš„ fallback
    DEFAULT_MODEL_OPTIONS = ["gemini-3-pro-image-preview"]
    print("[QueueManager] âš ï¸ æ— æ³•å¯¼å…¥ nano-banana-pro.pyï¼Œè¯·ç¡®ä¿æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")

# ================= å·¥å…·å‡½æ•°ï¼šå‚æ•°è§£æ =================

def parse_param_array(input_str: str, target_length: int, default_val, converter=str):
    """
    è§£æå‚æ•°å­—ç¬¦ä¸²ä¸ºåˆ—è¡¨ï¼Œå¹¶è‡ªåŠ¨å¡«å……/æˆªæ–­
    è¾“å…¥: "0, 1", target=4, default="0"
    è¾“å‡º: [0, 1, 1, 1] (ç±»å‹ç”± converter å†³å®š)
    """
    if not input_str or not str(input_str).strip():
        return [default_val] * target_length
    
    # 1. åˆ†å‰²å¹¶å»ç©º
    raw_list = [x.strip() for x in str(input_str).split(',')]
    
    # 2. è½¬æ¢ç±»å‹
    processed_list = []
    for x in raw_list:
        try:
            processed_list.append(converter(x))
        except:
            processed_list.append(default_val)
            
    if not processed_list:
        return [default_val] * target_length

    # 3. å¡«å……æˆ–æˆªæ–­
    current_len = len(processed_list)
    if current_len >= target_length:
        return processed_list[:target_length]
    else:
        # å¤åˆ¶æœ€åä¸€ä¸ªå…ƒç´ æ¥å¡«å……
        last_val = processed_list[-1]
        return processed_list + [last_val] * (target_length - current_len)

def format_queue_log(queue_data, current_status=""):
    """æ ¼å¼åŒ–é˜Ÿåˆ—çŠ¶æ€æ—¥å¿—"""
    log = f"=== ğŸ“Ÿ é˜Ÿåˆ—ç›‘æ§é¢æ¿ ({datetime.now().strftime('%H:%M:%S')}) ===\n"
    if current_status:
        log += f"â–¶ï¸ å½“å‰çŠ¶æ€: {current_status}\n"
    
    log += "\n" + "-"*30 + "\n"
    
    # å€’åºæ˜¾ç¤ºï¼Œæ–°çš„åœ¨ä¸Šé¢
    for idx, item in enumerate(reversed(queue_data)):
        real_idx = len(queue_data) - 1 - idx
        status_icon = {
            "pending": "â³ ç­‰å¾…ä¸­",
            "running": "ğŸ”„ æ‰§è¡Œä¸­",
            "completed": "âœ… å·²å®Œæˆ",
            "failed": "âŒ å·²å¤±è´¥",
            "partial": "âš ï¸ éƒ¨åˆ†å®Œæˆ"
        }.get(item['status'], item['status'])
        
        log += f"[{real_idx+1}] {status_icon} | æ‰¹æ¬¡: {item['done_count']}/{item['total_count']}\n"
        log += f"   ğŸ“ æç¤ºè¯: {item['prompt'][:30]}...\n"
        if item.get('error_msg'):
            log += f"   â— é”™è¯¯: {item['error_msg']}\n"
        log += "-"*30 + "\n"
            
    return log

# ================= æ ¸å¿ƒé€»è¾‘ï¼šå¸¦é‡è¯•çš„æ‰§è¡Œå™¨ =================

def execute_queue_task(
    prompt, ref_images, batch_count,
    param_arrays, # å­—å…¸ï¼šåŒ…å«æ‰€æœ‰å‚æ•°çš„åŸå§‹å­—ç¬¦ä¸²
    api_key, system_instruction,
    strategy_mode
):
    """
    ç”Ÿæˆå™¨å‡½æ•°ï¼šé€æ­¥æ‰§è¡Œé˜Ÿåˆ—ä»»åŠ¡å¹¶ yield çŠ¶æ€
    """
    from nano-banana--pro import call_gemini_vertex # å»¶è¿Ÿå¯¼å…¥
    
    results = []
    logs = []
    
    # 1. è§£ææ‰€æœ‰å‚æ•°æ•°ç»„
    # å°† "1:1, 16:9" è¿™ç§å­—ç¬¦ä¸²è§£æä¸ºå¯¹åº”æ¯æ¬¡å¾ªç¯çš„ list
    parsed_params = {
        "aspect_ratio": parse_param_array(param_arrays['aspect_ratio'], batch_count, "1:1"),
        "image_size": parse_param_array(param_arrays['image_size'], batch_count, "1K"),
        "enable_search": parse_param_array(param_arrays['enable_search'], batch_count, 0, int), # 0/1
        "temperature": parse_param_array(param_arrays['temperature'], batch_count, 0.9, float),
        "top_p": parse_param_array(param_arrays['top_p'], batch_count, 0.95, float),
        "top_k": parse_param_array(param_arrays['top_k'], batch_count, 40, int),
        "max_output_tokens": parse_param_array(param_arrays['max_output_tokens'], batch_count, 8192, int),
    }

    # 2. å¾ªç¯æ‰§è¡Œ
    for i in range(batch_count):
        current_prompt = prompt
        
        # --- ç­–ç•¥åº”ç”¨ ---
        if strategy_mode == "éšæœºå™ªå£° (Seed Salting)":
            seed = random.randint(10000, 99999)
            current_prompt = f"{prompt} \n(Random Seed: {seed}, Batch: {i+1})"
        elif strategy_mode == "è¯­ä¹‰é‡å†™ (Flash Rewrite)":
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è°ƒç”¨ flash æ¨¡å‹é‡å†™
            # æš‚æ—¶ç”¨ç®€å•çš„åç¼€æ¨¡æ‹Ÿ
            modifiers = ["Cinematic Lighting", "Wide Angle", "Close-up", "Cyberpunk Style", "Watercolor"]
            mod = modifiers[i % len(modifiers)]
            current_prompt = f"{prompt}, {mod}"
        
        # --- è·å–å½“å‰è½®æ¬¡çš„å‚æ•° ---
        cur_aspect = parsed_params["aspect_ratio"][i]
        cur_size = parsed_params["image_size"][i]
        cur_search = bool(parsed_params["enable_search"][i])
        cur_temp = parsed_params["temperature"][i]
        cur_top_p = parsed_params["top_p"][i]
        cur_top_k = parsed_params["top_k"][i]
        cur_tokens = parsed_params["max_output_tokens"][i]
        
        status_msg = f"æ­£åœ¨æ‰§è¡Œç¬¬ {i+1}/{batch_count} å¼ ... \nå°ºå¯¸: {cur_aspect} | æœç´¢: {cur_search} | Temp: {cur_temp}"
        yield results, i, status_msg, None # æ›´æ–°çŠ¶æ€

        # --- å¸¦æœ‰é”™è¯¯é€€è®©çš„ API è°ƒç”¨ ---
        max_retries = 3
        retry_delay = 5 # åˆå§‹ç­‰å¾…ç§’æ•°
        success = False
        
        for attempt in range(max_retries):
            try:
                # è°ƒç”¨ä¸»ç¨‹åºçš„å‡½æ•°
                # æ³¨æ„ï¼šhistory_messages ä¼ ç©ºï¼Œç¡®ä¿å•æ¬¡ç‹¬ç«‹ç”Ÿæˆ
                text_out, img_paths = call_gemini_vertex(
                    api_key=api_key,
                    model_name="gemini-3-pro-image-preview", # å¼ºåˆ¶ä½¿ç”¨ç”»å›¾æ¨¡å‹ï¼Œæˆ–è€…åšæˆå‚æ•°
                    history_messages=[], 
                    user_text=current_prompt,
                    user_images=ref_images,
                    aspect_ratio=cur_aspect,
                    image_size=cur_size,
                    system_instruction=system_instruction,
                    temperature=cur_temp,
                    top_p=cur_top_p,
                    top_k=cur_top_k,
                    max_output_tokens=cur_tokens,
                    enable_search=cur_search
                )
                
                if img_paths:
                    results.extend(img_paths)
                    success = True
                    break # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                else:
                    # å¦‚æœè¿”å›ç©ºï¼ˆå¯èƒ½æ˜¯è¢«æ‹¦æˆªï¼‰ï¼Œè§†ä¸ºéè‡´å‘½é”™è¯¯ï¼Œä¸é‡è¯•ï¼Œç›´æ¥ä¸‹ä¸€å¼ 
                    print(f"[Queue] ç¬¬ {i+1} å¼ æœªç”Ÿæˆå›¾ç‰‡: {text_out}")
                    break 

            except Exception as e:
                err_str = str(e)
                print(f"[Queue Error] Attempt {attempt+1}: {err_str}")
                
                # === é”™è¯¯åˆ†ç±»å¤„ç† ===
                if "429" in err_str or "RESOURCE_EXHAUSTED" in err_str:
                    wait_time = retry_delay * (2 ** attempt) # æŒ‡æ•°é€€é¿: 5s, 10s, 20s
                    yield results, i, f"âš ï¸ è§¦å‘é™æµ (429)ï¼Œå†·å´ {wait_time} ç§’...", None
                    time.sleep(wait_time)
                    continue # é‡è¯•
                
                elif "400" in err_str or "INVALID_ARGUMENT" in err_str:
                    yield results, i, f"âŒ å‚æ•°é”™è¯¯ (400)ï¼Œè·³è¿‡æœ¬ä»»åŠ¡...", f"400 Error: {err_str}"
                    # 400 é”™è¯¯é€šå¸¸æ— æ³•é€šè¿‡é‡è¯•è§£å†³ï¼ˆå¦‚å‚æ•°ä¸å¯¹ï¼‰ï¼Œç›´æ¥è·³å‡ºé‡è¯•ï¼Œç”šè‡³å¯ä»¥ return ç»ˆæ­¢æ•´ä¸ª batch
                    # è¿™é‡Œé€‰æ‹©è·³è¿‡å½“å‰è¿™å¼ ï¼Œç»§ç»­ä¸‹ä¸€å¼ 
                    success = False
                    break 
                
                else:
                    # å…¶ä»–æœªçŸ¥é”™è¯¯ï¼Œå°è¯•é‡è¯•
                    wait_time = 5
                    time.sleep(wait_time)
        
        if not success:
            # å¦‚æœé‡è¯•å¤šæ¬¡ä¾ç„¶å¤±è´¥
            pass
            
        # å¼ºåˆ¶å†·å´ä¸€å°ä¼šå„¿ï¼Œé¿å…è¿ç»­è¯·æ±‚è¿‡äºå¯†é›†
        time.sleep(2)

    yield results, batch_count, "ä»»åŠ¡å®Œæˆ", None


# ================= Gradio ç•Œé¢æ„å»º =================

def process_queue_click(
    prompt, ref_images, batch_count, strategy,
    ar_arr, size_arr, search_arr, temp_arr, top_p_arr, top_k_arr, token_arr,
    api_key, sys_inst,
    queue_data
):
    """
    å“åº”â€œåŠ å…¥é˜Ÿåˆ—å¹¶æ‰§è¡Œâ€æŒ‰é’®
    """
    # 1. æ–°å»ºä»»åŠ¡å¯¹è±¡
    new_task = {
        "id": int(time.time()),
        "prompt": prompt,
        "total_count": int(batch_count),
        "done_count": 0,
        "status": "pending", # pending -> running -> completed/failed
        "error_msg": ""
    }
    
    queue_data = queue_data or []
    queue_data.append(new_task)
    
    # 2. æ›´æ–°æ—¥å¿—æ˜¾ç¤º (Pending)
    yield queue_data, format_queue_log(queue_data, "å‡†å¤‡å¼€å§‹..."), []
    
    # 3. å¼€å§‹æ‰§è¡Œ
    # æ›´æ–°å½“å‰ä»»åŠ¡çŠ¶æ€ä¸º running
    queue_data[-1]['status'] = "running"
    
    param_arrays = {
        "aspect_ratio": ar_arr, "image_size": size_arr, "enable_search": search_arr,
        "temperature": temp_arr, "top_p": top_p_arr, "top_k": top_k_arr, "max_output_tokens": token_arr
    }
    
    try:
        # è°ƒç”¨ç”Ÿæˆå™¨
        iterator = execute_queue_task(
            prompt, ref_images, int(batch_count), param_arrays,
            api_key, sys_inst, strategy
        )
        
        for img_results, done_idx, status_text, err in iterator:
            # å®æ—¶æ›´æ–°çŠ¶æ€
            queue_data[-1]['done_count'] = done_idx
            
            if err:
                queue_data[-1]['error_msg'] = err
            
            # åˆ·æ–°ç•Œé¢
            log_str = format_queue_log(queue_data, status_text)
            yield queue_data, log_str, img_results
            
        # å®Œæˆ
        queue_data[-1]['status'] = "completed" if not queue_data[-1].get('error_msg') else "partial"
        yield queue_data, format_queue_log(queue_data, "âœ… æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•"), img_results
        
    except Exception as e:
        traceback.print_exc()
        queue_data[-1]['status'] = "failed"
        queue_data[-1]['error_msg'] = str(e)
        yield queue_data, format_queue_log(queue_data, "âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿè‡´å‘½é”™è¯¯"), []


def create_tab():
    with gr.Tab("ğŸ“š æ™ºèƒ½é˜Ÿåˆ— (Smart Queue)"):
        gr.Markdown("### ğŸ› ï¸ æ‰¹é‡ç”Ÿæˆä¸å‚æ•°çŸ©é˜µ")
        
        # çŠ¶æ€å­˜å‚¨
        queue_state = gr.State([]) 
        
        with gr.Row():
            # --- å·¦ä¾§ï¼šæ§åˆ¶é¢æ¿ ---
            with gr.Column(scale=4):
                
                # 1. çŠ¶æ€ç›‘æ§
                log_box = gr.TextArea(
                    label="é˜Ÿåˆ—çŠ¶æ€ç›‘æ§", 
                    value="ç­‰å¾…ä»»åŠ¡...", 
                    lines=8, 
                    max_lines=10,
                    interactive=False,
                    elem_id="queue-log"
                )
                
                # 2. åŸºç¡€è¾“å…¥ (ä¸ä¸»ç•Œé¢ä¸€è‡´)
                prompt_input = gr.Textbox(label="æç¤ºè¯ (Prompt)", lines=3, placeholder="è¾“å…¥ç”»é¢æè¿°...")
                ref_image_input = gr.File(label="å‚è€ƒå›¾ç‰‡ (å¯é€‰)", file_count="multiple", type="filepath")
                
                with gr.Row():
                    batch_slider = gr.Slider(label="æ‰§è¡Œæ¬¡æ•° (Batch Size)", minimum=1, maximum=9, value=4, step=1)
                    strategy_radio = gr.Radio(
                        label="å·®å¼‚åŒ–ç­–ç•¥", 
                        choices=["éšæœºå™ªå£° (Seed Salting)", "è¯­ä¹‰é‡å†™ (Flash Rewrite)", "ä»…å‚æ•°å˜åŒ–"], 
                        value="éšæœºå™ªå£° (Seed Salting)"
                    )
                
                # 3. é«˜çº§å‚æ•°çŸ©é˜µ (Accordion æŠ˜å )
                with gr.Accordion("ğŸ“ å‚æ•°çŸ©é˜µ (æ•°ç»„æ¨¡å¼)", open=False):
                    gr.Markdown(
                        "è¾“å…¥ä»¥é€—å·åˆ†éš”çš„å€¼ (ä¾‹å¦‚ `0, 1, 1`)ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨å¯¹åº”åˆ°æ¯ä¸€æ¬¡å¾ªç¯ã€‚\n"
                        "å¦‚æœå€¼çš„æ•°é‡å°‘äºæ‰§è¡Œæ¬¡æ•°ï¼Œä¼šè‡ªåŠ¨å¤åˆ¶æœ€åä¸€ä¸ªå€¼è¡¥å…¨ã€‚"
                    )
                    with gr.Row():
                        ar_input = gr.Textbox(label="å®½é«˜æ¯” (Aspect Ratio)", value="1:1, 16:9", placeholder="1:1, 16:9...")
                        size_input = gr.Textbox(label="å°ºå¯¸ (Size)", value="1K", placeholder="1K, 2K...")
                    
                    with gr.Row():
                        search_input = gr.Textbox(label="æ˜¯å¦æœç´¢ (0=å¦, 1=æ˜¯)", value="0", placeholder="0, 1, 0...")
                        temp_input = gr.Textbox(label="Temperature", value="0.9, 1.2", placeholder="0.9, 1.2...")
                    
                    with gr.Row():
                        topp_input = gr.Textbox(label="Top P", value="0.95")
                        topk_input = gr.Textbox(label="Top K", value="40")
                        token_input = gr.Textbox(label="Max Tokens", value="8192")

                # 4. éšè—çš„ API Key è¾“å…¥ (ä»ä¸» Tab ä¼ é€’è¿‡æ¥æ¯”è¾ƒéº»çƒ¦ï¼Œè¿™é‡Œç®€å•å†æ”¾ä¸€ä¸ªæˆ–é»˜è®¤è¯»å–ç¯å¢ƒå˜é‡)
                # ä¸ºäº†ç®€ä¾¿ï¼Œå»ºè®®ç”¨æˆ·åœ¨ä¸» Tab å¡«å¥½ Keyï¼Œè¿™é‡Œç›´æ¥ç”¨ç¯å¢ƒå˜é‡ï¼Œæˆ–è€…å†æ”¾ä¸€ä¸ª Textbox
                api_key_input = gr.Textbox(label="API Key (å¦‚æœªè®¾ç½®ç¯å¢ƒå˜é‡è¯·åœ¨æ­¤è¾“å…¥)", type="password")
                sys_inst_input = gr.Textbox(label="ç³»ç»ŸæŒ‡ä»¤", value="", lines=1)

                btn_run = gr.Button("ğŸš€ åŠ å…¥é˜Ÿåˆ—å¹¶å¯åŠ¨", variant="primary")

            # --- å³ä¾§ï¼šç»“æœç”»å»Š ---
            with gr.Column(scale=5):
                gallery = gr.Gallery(label="ç”Ÿæˆç»“æœ", columns=3, height=800, object_fit="contain")

        # äº‹ä»¶ç»‘å®š
        btn_run.click(
            fn=process_queue_click,
            inputs=[
                prompt_input, ref_image_input, batch_slider, strategy_radio,
                ar_input, size_input, search_input, temp_input, topp_input, topk_input, token_input,
                api_key_input, sys_inst_input,
                queue_state
            ],
            outputs=[queue_state, log_box, gallery]
        )
